{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "from diffusers import DiffusionPipeline, DDIMScheduler, DDPMScheduler\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from ProteinDiffusion.models.UNet1DProtein import UNet1DProtein\n",
    "import torch\n",
    "\n",
    "class VaeProteinProcessor(ConfigMixin):\n",
    "    # https://github.com/huggingface/diffusers/blob/main/src/diffusers/image_processor.py#L60\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.register_modules(unet=unet, scheduler=scheduler)\n",
    "\n",
    "def latent_to_seq(latents: torch.Tensor) -> torch.Tensor:\n",
    "    latents = latents.clamp(-1, 1)\n",
    "    latents = (latents + 1) / 2\n",
    "    return latents\n",
    "\n",
    "class ProteinDiffusionPipeline(DiffusionPipeline):\n",
    "    def __init__(self, \n",
    "                 unet: UNet1DProtein,\n",
    "                 scheduler: Union[DDPMScheduler],\n",
    "                 aa_encoder: PreTrainedTokenizerFast,\n",
    "                 aa_decoder: Tokenizer,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.register_modules(unet=unet, scheduler=scheduler)\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        seq_length: Optional[int] = 256,\n",
    "        num_inference_steps: Optional[int] = 50,\n",
    "        generator: Optional[torch.Generator] = None,\n",
    "        batch_size: Optional[int] = 1,\n",
    "        output_type: Optional[str] = \"aa\",\n",
    "        return_dict: bool = True,\n",
    "        **kwargs,\n",
    "    ) -> Union[Tuple]:\n",
    "        latents = torch.randn(\n",
    "            (batch_size, \n",
    "             self.unet.config.in_channels, \n",
    "             seq_length\n",
    "             ),\n",
    "            generator=generator,\n",
    "        )\n",
    "\n",
    "        latents = latents.to(self.device)\n",
    "\n",
    "        self.scheduler.set_timesteps(num_inference_steps)\n",
    "\n",
    "        for t in self.progress_bar(self.scheduler.timesteps):\n",
    "            # predict the noise residual\n",
    "            noise_pred = self.unet(latents, t).sample\n",
    "\n",
    "            # compute the previous noisy sample x_t -> x_t-1\n",
    "            latents = self.scheduler.step(noise_pred, t, latents).prev_sample\n",
    "\n",
    "        latents = latent_to_seq(latents)\n",
    "\n",
    "        if output_type == \"aa\":\n",
    "            seq = self.aa_decoder.decode(latents)\n",
    "\n",
    "        if not return_dict:\n",
    "            return (seq,)\n",
    "\n",
    "        return ImagePipelineOutput(images=image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
