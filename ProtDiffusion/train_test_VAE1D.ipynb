{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    batch_size = 64  # the batch size\n",
    "    mega_batch = 1000 # how many batches to use for batchsampling\n",
    "    num_epochs = 100  # the number of epochs to train the model\n",
    "    gradient_accumulation_steps = 2\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    save_image_epochs = 10\n",
    "    save_model_epochs = 30\n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"protein-VAE-UniRef50-M\"  # the model name locally and on the HF Hub\n",
    "    pad_to_multiple_of = 16\n",
    "    max_len = 512  # truncation of the input sequence\n",
    "\n",
    "    class_embeddings_concat = False  # whether to concatenate the class embeddings to the time embeddings\n",
    "\n",
    "    push_to_hub = False  # whether to upload the saved model to the HF Hub\n",
    "    hub_model_id = \"kkj15dk/protein-VAE_test\"  # the name of the repository to create on the HF Hub\n",
    "    hub_private_repo = False\n",
    "    overwrite_output_dir = True  # overwrite the old model when re-running the notebook\n",
    "    seed = 42\n",
    "\n",
    "    labels_file = 'labels_test.json'\n",
    "\n",
    "    cutoff = None # cutoff for when to predict the token given the logits, and when to assign the unknown token 'X' to this position\n",
    "    skip_special_tokens = False # whether to skip the special tokens when writing the evaluation sequences\n",
    "    kl_weight = 0.05 # the weight of the KL divergence in the loss function\n",
    "\n",
    "\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb9116c685d45f0b0706613a0ab0b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51edbb03ac5043c1afb6bef396c35e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# config.dataset_name = \"kkj15dk/test_dataset\"\n",
    "config.dataset_name = \"agemagician/uniref50\"\n",
    "dataset = load_dataset(config.dataset_name) # , download_mode='force_redownload')\n",
    "dataset = dataset.shuffle(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"kkj15dk/protein_tokenizer\")\n",
    "\n",
    "def encode(example):\n",
    "    return tokenizer(example['text'],\n",
    "    # return tokenizer(example['sequence'],\n",
    "                    padding = True,\n",
    "                    pad_to_multiple_of = config.pad_to_multiple_of,\n",
    "                    return_token_type_ids=False,\n",
    "                    return_attention_mask=False, # We need to attend to padding tokens, so we set this to False\n",
    ")\n",
    "# dataset_train = dataset['train'].map(encode, batched=False, remove_columns=[\"sequence\"])\n",
    "# dataset_test = dataset['test'].map(encode, batched=False, remove_columns=[\"sequence\"])\n",
    "# dataset_val = dataset['val'].map(encode, batched=False, remove_columns=[\"sequence\"])\n",
    "\n",
    "# dataset_train = dataset['train'].map(encode, batched=False, remove_columns=[\"text\"])\n",
    "dataset_test = dataset['test'].map(encode, batched=False, remove_columns=[\"text\"])\n",
    "dataset_val = dataset['validation'].map(encode, batched=False, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'name', 'input_ids'],\n",
      "    num_rows: 5888\n",
      "})\n",
      "[0, 13, 20, 17, 17, 20, 18, 7, 3, 18, 5, 3, 20, 15, 12, 15, 3, 19, 20, 18, 16, 6, 16, 20, 6, 17, 15, 12, 17, 18, 12, 12, 17, 18, 11, 15, 18, 12, 17, 21, 3, 20, 4, 3, 13, 20, 12, 18, 8, 12, 8, 13, 3, 13, 7, 3, 3, 20, 18, 20, 12, 21, 12, 16, 3, 3, 12, 8, 21, 5, 8, 6, 6, 20, 8, 12, 7, 12, 18, 7, 8, 18, 4, 12, 16, 12, 20, 18, 16, 20, 20, 20, 12, 15, 4, 12, 7, 11, 10, 19, 17, 21, 17, 6, 10, 17, 20, 3, 11, 10, 4, 12, 10, 3, 14, 3, 7, 11, 7, 13, 3, 12, 4, 18, 20, 16, 5, 18, 17, 21, 20, 7, 3, 10, 12, 10, 3, 3, 3, 15, 8, 7, 4, 8, 19, 15, 20, 12, 7, 18, 12, 4, 19, 9, 16, 20, 15, 11, 3, 5, 11, 17, 17, 21, 9, 7, 3, 12, 19, 3, 12, 14, 19, 20, 3, 19, 20, 12, 8, 3, 12, 3, 8, 18, 9, 12, 12, 20, 12, 8, 12, 16, 8, 18, 17, 15, 12, 8, 19, 15, 12, 7, 7, 3, 3, 3, 4, 22, 7, 12, 3, 8, 8, 4, 15, 8, 1, 23, 23, 23, 23, 23, 23, 23]\n",
      "UniRef50_A0A7S0FGK4\n",
      "224\n",
      "[MVRRVSFASDAVPLPATVSQEQVERPLRSLLRSKPSLRWAVCAMVLSGLGMAMFAAVSVLWLQAALGWDGEEVGLFLSFGSCLQLVSQVVVLPCLFKITRWREIRVAKICLIANAFKFMALCSVQDSRWVFAILIAAAPGFCGTPVLFSLCTHQVPKADKRRWHFALTALNTVATVLGALAGSHLLVLGLQGSRPLGTPLFFAAACYFLAGGCPG]-------\n",
      "MVRRVSFASDAVPLPATVSQEQVERPLRSLLRSKPSLRWAVCAMVLSGLGMAMFAAVSVLWLQAALGWDGEEVGLFLSFGSCLQLVSQVVVLPCLFKITRWREIRVAKICLIANAFKFMALCSVQDSRWVFAILIAAAPGFCGTPVLFSLCTHQVPKADKRRWHFALTALNTVATVLGALAGSHLLVLGLQGSRPLGTPLFFAAACYFLAGGCPG\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test)\n",
    "print(dataset_test[0]['input_ids'])\n",
    "print(dataset_test[0]['name'])\n",
    "print(len(dataset_test[0]['input_ids']))\n",
    "print(tokenizer.decode(dataset_test[0]['input_ids'], skip_special_tokens=False))\n",
    "print(tokenizer.decode(dataset_test[0]['input_ids'], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 224])\n",
      "tensor([[ 0, 13, 20, 17, 17, 20, 18,  7,  3, 18,  5,  3, 20, 15, 12, 15,  3, 19,\n",
      "         20, 18, 16,  6, 16, 20,  6, 17, 15, 12, 17, 18, 12, 12, 17, 18, 11, 15,\n",
      "         18, 12, 17, 21,  3, 20,  4,  3, 13, 20, 12, 18,  8, 12,  8, 13,  3, 13,\n",
      "          7,  3,  3, 20, 18, 20, 12, 21, 12, 16,  3,  3, 12,  8, 21,  5,  8,  6,\n",
      "          6, 20,  8, 12,  7, 12, 18,  7,  8, 18,  4, 12, 16, 12, 20, 18, 16, 20,\n",
      "         20, 20, 12, 15,  4, 12,  7, 11, 10, 19, 17, 21, 17,  6, 10, 17, 20,  3,\n",
      "         11, 10,  4, 12, 10,  3, 14,  3,  7, 11,  7, 13,  3, 12,  4, 18, 20, 16,\n",
      "          5, 18, 17, 21, 20,  7,  3, 10, 12, 10,  3,  3,  3, 15,  8,  7,  4,  8,\n",
      "         19, 15, 20, 12,  7, 18, 12,  4, 19,  9, 16, 20, 15, 11,  3,  5, 11, 17,\n",
      "         17, 21,  9,  7,  3, 12, 19,  3, 12, 14, 19, 20,  3, 19, 20, 12,  8,  3,\n",
      "         12,  3,  8, 18,  9, 12, 12, 20, 12,  8, 12, 16,  8, 18, 17, 15, 12,  8,\n",
      "         19, 15, 12,  7,  7,  3,  3,  3,  4, 22,  7, 12,  3,  8,  8,  4, 15,  8,\n",
      "          1, 23, 23, 23, 23, 23, 23, 23]])\n",
      "['[MVRRVSFASDAVPLPATVSQEQVERPLRSLLRSKPSLRWAVCAMVLSGLGMAMFAAVSVLWLQAALGWDGEEVGLFLSFGSCLQLVSQVVVLPCLFKITRWREIRVAKICLIANAFKFMALCSVQDSRWVFAILIAAAPGFCGTPVLFSLCTHQVPKADKRRWHFALTALNTVATVLGALAGSHLLVLGLQGSRPLGTPLFFAAACYFLAGGCPG]-------']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_ids_tensor = torch.tensor(dataset_test[0]['input_ids'], dtype=torch.long)\n",
    "onehot_seq = F.one_hot(input_ids_tensor, num_classes=tokenizer.vocab_size + 1).permute(1, 0).unsqueeze(0)\n",
    "print(onehot_seq.shape)\n",
    "\n",
    "def logits_to_token_ids(tokenizer, logits, cutoff = None):\n",
    "        '''\n",
    "        Convert a batch of logits to token_ids.\n",
    "        Returns token_ids\n",
    "        '''\n",
    "        if cutoff is None:\n",
    "            token_ids = logits.argmax(dim=1)\n",
    "        else:\n",
    "            token_ids = torch.where(logits.max(dim=1).values > cutoff, \n",
    "                                    logits.argmax(dim=1), \n",
    "                                    torch.tensor([tokenizer.unknown_token_id])\n",
    "                                    )\n",
    "\n",
    "        return token_ids\n",
    "token_ids = logits_to_token_ids(tokenizer, onehot_seq)\n",
    "print(token_ids)\n",
    "print(tokenizer.batch_decode(token_ids, skip_special_tokens=config.skip_special_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def collate_fn(batch): # Can definitely be optimized\n",
    "    max_len = max(len(x['input_ids']) for x in batch)\n",
    "    if max_len > config.max_len:\n",
    "        max_len = config.max_len\n",
    "    input_ids = torch.zeros(len(batch), max_len, dtype=torch.long)\n",
    "    attention_mask = torch.zeros(len(batch), max_len, dtype=torch.float)\n",
    "    class_labels = torch.zeros(len(batch), dtype=torch.long)\n",
    "    # identifiers = [x['id'] for x in batch]\n",
    "    identifiers = [x.get('name', 'N/A') for x in batch]\n",
    "    for i, x in enumerate(batch):\n",
    "        seq_len = len(x['input_ids'])\n",
    "        if seq_len > max_len:\n",
    "            index = random.randint(0, seq_len - max_len)\n",
    "            x['input_ids'] = x['input_ids'][index:index+max_len]\n",
    "            seq_len = max_len\n",
    "        input_ids[i, :seq_len] = torch.tensor(x['input_ids'], dtype=torch.long)\n",
    "        attention_mask[i, :seq_len] = torch.tensor(1, dtype=torch.float)\n",
    "        # class_labels[i] = torch.tensor(x['class'], dtype=torch.long)\n",
    "    return {'id': identifiers, 'input_ids': input_ids, 'attention_mask': attention_mask, 'class_label': class_labels}\n",
    "\n",
    "class BatchSampler:\n",
    "    '''\n",
    "    BatchSampler for variable length sequences, batching by similar lengths, to prevent excessive padding.\n",
    "    '''\n",
    "    def __init__(self, lengths, batch_size, mega_batch_size, drop_last = True):\n",
    "        self.lengths = lengths\n",
    "        self.batch_size = batch_size\n",
    "        self.mega_batch_size = mega_batch_size\n",
    "        self.drop_last = drop_last\n",
    "\n",
    "    def __iter__(self):\n",
    "        size = len(self.lengths)\n",
    "        indices = list(range(size))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        step = self.mega_batch_size * self.batch_size\n",
    "        for i in range(0, size, step):\n",
    "            pool = indices[i:i+step]\n",
    "            pool = sorted(pool, key=lambda x: self.lengths[x])\n",
    "            mega_batch_indices = list(range(0, len(pool), self.batch_size))\n",
    "            random.shuffle(mega_batch_indices) # shuffle the mega batches, so that the model doesn't see the same order of lengths every time. The small batch will however always be the one with longest lengths\n",
    "            for j in mega_batch_indices:\n",
    "                if self.drop_last and j + self.batch_size > len(pool): # drop the last batch if it's too small\n",
    "                    continue\n",
    "                batch = pool[j:j+self.batch_size]\n",
    "                random.shuffle(batch) # shuffle the batch, so that the model doesn't see the same order of lengths every time\n",
    "                yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return len(self.lengths) // self.batch_size\n",
    "        else:\n",
    "            return (len(self.lengths) + self.batch_size - 1) // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max val length: 6064\n",
      "Max test length: 13616\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timeit\n",
    "\n",
    "val_lengths = list(map(lambda x: len(x[\"input_ids\"]), dataset_val))\n",
    "print(\"Max val length:\", max(val_lengths))\n",
    "test_lengths = list(map(lambda x: len(x[\"input_ids\"]), dataset_test))\n",
    "print(\"Max test length:\", max(test_lengths))\n",
    "# train_lengths = list(map(lambda x: len(x[\"input_ids\"]), dataset_train))\n",
    "# print(\"Max val length:\", max(val_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataloader = DataLoader(dataset_train, \n",
    "#                             batch_sampler=BatchSampler(train_lengths, \n",
    "#                                                     config.batch_size,\n",
    "#                                                     config.mega_batch,\n",
    "#                                                     drop_last=False), \n",
    "#                             collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(dataset_test,\n",
    "                            batch_sampler=BatchSampler(test_lengths, \n",
    "                                                    config.batch_size,\n",
    "                                                    config.mega_batch,\n",
    "                                                    drop_last=False), \n",
    "                            collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(dataset_val, \n",
    "                            batch_sampler=BatchSampler(val_lengths, \n",
    "                                                    config.batch_size,\n",
    "                                                    config.mega_batch,\n",
    "                                                    drop_last=False),\n",
    "                            collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from New1D.autoencoder_kl_1d import AutoencoderKL1D\n",
    "\n",
    "model = AutoencoderKL1D(\n",
    "    num_class_embeds=tokenizer.vocab_size + 1,  # the number of class embeddings\n",
    "    \n",
    "    down_block_types=(\n",
    "        \"DownEncoderBlock1D\",  # a regular ResNet downsampling block\n",
    "        \"DownEncoderBlock1D\",\n",
    "        \"AttnDownEncoderBlock1D\",\n",
    "        \"AttnDownEncoderBlock1D\",  # a ResNet downsampling block with spatial self-attention\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"AttnUpDecoderBlock1D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"AttnUpDecoderBlock1D\",\n",
    "        \"UpDecoderBlock1D\",\n",
    "        \"UpDecoderBlock1D\",  # a regular ResNet upsampling block\n",
    "    ),\n",
    "    block_out_channels=(64, 128, 256, 512),  # the number of output channels for each block\n",
    "    mid_block_type=\"UNetMidBlock1D\",  # the type of the middle block\n",
    "    mid_block_channels=1024,  # the number of output channels for the middle block\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    transformer_layers_per_block=1, # how many transformer layers to use per ResNet layer. Not implemented yet.\n",
    "\n",
    "    latent_channels=32,  # the dimensionality of the latent space\n",
    "\n",
    "    num_attention_heads=4,  # the number of attention heads in the spatial self-attention blocks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75875896"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.children\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'input_ids', 'attention_mask', 'class_label'])\n",
      "UniRef50_A0A1F3NL17\n",
      "tensor([ 0, 13, 14, 17, 10, 12, 10, 12, 12, 12, 10, 19, 10, 12, 19, 20, 18,  4,\n",
      "        18, 11, 18, 17, 18,  5, 15, 11, 17, 20,  3, 20,  3, 17,  3,  8, 14, 20,\n",
      "         7, 12, 22,  9,  5, 16, 10, 15, 17, 13, 10, 15, 15,  8, 19, 18, 15,  3,\n",
      "         5, 18,  3,  3, 10, 20,  9, 14, 22, 10, 14, 17, 21,  3, 17, 11,  6,  7,\n",
      "        12, 17, 16, 11,  3, 16,  6, 14, 12, 18,  3,  5, 12, 11, 10,  6, 10,  5,\n",
      "        14, 16, 12,  6,  6, 19, 17, 18, 14, 12, 20, 10, 22, 16, 22, 16, 17, 16,\n",
      "        13, 13, 12,  6, 17, 13,  5, 19, 10, 12, 19,  6,  3,  6, 12,  6, 16, 22,\n",
      "        22, 12,  5, 14, 16,  6, 18,  7, 13, 12, 14, 18, 14, 10, 10, 11,  3, 12,\n",
      "         7, 10, 11, 12, 15,  3,  6, 19, 15, 14, 10, 18, 17, 10, 17, 12, 12,  3,\n",
      "        17, 18, 14,  6, 16,  6,  5, 12, 16,  6, 12,  6, 18, 22,  4, 22, 16,  7,\n",
      "         3,  5, 11,  7,  5,  5,  7, 14,  6, 11, 21, 20, 15,  7, 14, 17, 12, 18,\n",
      "        20,  6, 12, 15, 16,  5, 10, 15, 14,  6,  6, 18,  1, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "sample_image = next(iter(val_dataloader))\n",
    "print(sample_image.keys())\n",
    "print(sample_image['id'][0])\n",
    "print(sample_image['input_ids'][0])\n",
    "print(sample_image['attention_mask'][0])\n",
    "print(sample_image['class_label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([1, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class_labels = sample_image['class_label'][0].unsqueeze(0)\n",
    "attention_mask = sample_image['attention_mask'][0].unsqueeze(0)\n",
    "print(class_labels.shape)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "input_ids = sample_image['input_ids']\n",
    "attention_mask = sample_image['attention_mask']\n",
    "\n",
    "output = model(sample = input_ids,\n",
    "                attention_mask = attention_mask,\n",
    "                sample_posterior = True, # Should be set to true in training\n",
    ")\n",
    "\n",
    "def loss_fn(output, input_ids\n",
    "    ) -> tuple[torch.Tensor]:\n",
    "    ce_loss = F.cross_entropy(output.sample, input_ids, reduction='none')\n",
    "    ce_loss = torch.sum(\n",
    "        ce_loss * output.attention_masks[0]\n",
    "    ) / output.attention_masks[0].sum()\n",
    "    \n",
    "    kl_loss = output.latent_dist.kl()\n",
    "    kl_loss = torch.sum(\n",
    "        kl_loss * output.attention_masks[-1]\n",
    "    ) / output.attention_masks[-1].sum()\n",
    "\n",
    "    return ce_loss, kl_loss\n",
    "\n",
    "# loss = loss_fn(output, input_ids)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    # num_training_steps=(len(test_dataloader) * config.num_epochs),\n",
    "    num_training_steps=(len(test_dataloader) * config.num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -1, val_loss: 3.1802, val_accuracy: 0.0361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 3.1801769733428955,\n",
       " 'val_ce_loss': 3.1783790588378906,\n",
       " 'val_kl_loss': 0.03595801442861557,\n",
       " 'val_acc': 0.03606510380042623}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(config, epoch, output, dataloader, output_dir: Optional[str] = None\n",
    "    ) -> float:\n",
    "\n",
    "    if output_dir is not None:\n",
    "        test_dir = os.path.join(config.output_dir, \"samples\")\n",
    "        os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    num_correct_residues = 0\n",
    "    total_residues = 0\n",
    "\n",
    "    for i, sample in enumerate(dataloader):\n",
    "\n",
    "        output = model(sample = sample['input_ids'],\n",
    "                            attention_mask = sample['attention_mask'],\n",
    "                            sample_posterior = False, # Should be set to true in training\n",
    "        )\n",
    "\n",
    "        ce_loss, kl_loss = loss_fn(output, sample['input_ids'])\n",
    "        loss = ce_loss + kl_loss * config.kl_weight\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        token_ids_pred = logits_to_token_ids(tokenizer, output.sample, cutoff = config.cutoff)\n",
    "\n",
    "        token_ids_correct = ((sample['input_ids'] == token_ids_pred) & (sample['attention_mask'] == 1)).long()\n",
    "        num_residues = torch.sum(sample['attention_mask'], dim=1).long()\n",
    "\n",
    "        num_correct_residues += token_ids_correct.sum().item()\n",
    "        total_residues += num_residues.sum().item()\n",
    "\n",
    "        # Decode the predicted sequences, and remove zero padding\n",
    "        seqs_pred = tokenizer.batch_decode(token_ids_pred, skip_special_tokens=config.skip_special_tokens)\n",
    "        seqs_lens = torch.sum(sample['attention_mask'], dim=1).long()\n",
    "        seqs_pred = [seq[:i] for seq, i in zip(seqs_pred, seqs_lens)]\n",
    "\n",
    "        # Save all samples as a FASTA file\n",
    "        seq_record_list = [SeqRecord(Seq(seq), id=str(sample['id'][i]), \n",
    "                        description=\n",
    "                        f\"classlabel: {sample['class_label'][i].item()} acc: {token_ids_correct[i].sum().item() / num_residues[i].item():.2f}\")\n",
    "                        for i, seq in enumerate(seqs_pred)]\n",
    "        with open(f\"{test_dir}/{epoch:04d}.fa\", \"a\") as f:\n",
    "            SeqIO.write(seq_record_list, f, \"fasta\")\n",
    "    \n",
    "    acc = num_correct_residues / total_residues\n",
    "    print(f\"Epoch {epoch}, val_loss: {running_loss / len(dataloader):.4f}, val_accuracy: {acc:.4f}\")\n",
    "    logs = {\"val_loss\": loss.detach().item(), \n",
    "            \"val_ce_loss\": ce_loss.detach().item(), \n",
    "            \"val_kl_loss\": kl_loss.detach().item(),\n",
    "            \"val_acc\": acc,\n",
    "            }\n",
    "    return logs\n",
    "\n",
    "evaluate(config, -1, model, val_dataloader, output_dir = config.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from huggingface_hub import create_repo, upload_folder\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "def train_loop(config, model, optimizer, train_dataloader, test_dataloader, lr_scheduler):\n",
    "    # Initialize accelerator and tensorboard logging\n",
    "    accelerator = Accelerator(\n",
    "        mixed_precision=config.mixed_precision,\n",
    "        gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "        log_with=\"tensorboard\",\n",
    "        project_dir=os.path.join(config.output_dir, \"logs\"),\n",
    "    )\n",
    "    if accelerator.is_main_process:\n",
    "        if config.output_dir is not None:\n",
    "            os.makedirs(config.output_dir, exist_ok=True)\n",
    "        if config.push_to_hub:\n",
    "            repo_id = create_repo(\n",
    "                repo_id=config.hub_model_id or Path(config.output_dir).name, exist_ok=True\n",
    "            ).repo_id\n",
    "        accelerator.init_trackers(\"train_example\")\n",
    "\n",
    "    # Prepare everything\n",
    "    # There is no specific order to remember, you just need to unpack the\n",
    "    # objects in the same order you gave them to the prepare method.\n",
    "    model, optimizer, train_dataloader, test_dataloader, lr_scheduler = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, test_dataloader, lr_scheduler\n",
    "    )\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    # Now you train the model\n",
    "    for epoch in range(config.num_epochs):\n",
    "        progress_bar = tqdm(total=len(train_dataloader), disable=not accelerator.is_local_main_process)\n",
    "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            with accelerator.accumulate(model):\n",
    "                input = batch['input_ids']\n",
    "                attention_mask = batch['attention_mask']\n",
    "                # Predict the noise residual\n",
    "                output = model(sample = input,\n",
    "                                attention_mask = attention_mask,\n",
    "                                sample_posterior = True, # Should be set to true in training\n",
    "                )\n",
    "                ce_loss, kl_loss = loss_fn(output, input)\n",
    "                loss = ce_loss + kl_loss * config.kl_weight\n",
    "                accelerator.backward(loss)\n",
    "\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            logs = {\"train_loss\": loss.detach().item(), \n",
    "                    \"train_ce_loss\": ce_loss.detach().item(), \n",
    "                    \"train_kl_loss\": kl_loss.detach().item(), \n",
    "                    \"lr\": lr_scheduler.get_last_lr()[0], \n",
    "                    \"step\": global_step,\n",
    "            }\n",
    "            progress_bar.set_postfix(**logs)\n",
    "            accelerator.log(logs, step=global_step)\n",
    "            global_step += 1\n",
    "\n",
    "        # After each epoch you optionally sample some demo images with evaluate() and save the model\n",
    "        if accelerator.is_main_process:\n",
    "\n",
    "            if (epoch + 1) % config.save_image_epochs == 0 or epoch == config.num_epochs - 1:\n",
    "                \n",
    "                logs = evaluate(config, epoch, model, test_dataloader, output_dir = config.output_dir)\n",
    "                accelerator.log(logs, step=global_step)\n",
    "\n",
    "                if config.push_to_hub:\n",
    "                    upload_folder(\n",
    "                        repo_id=repo_id,\n",
    "                        folder_path=config.output_dir,\n",
    "                        commit_message=f\"Epoch {epoch}\",\n",
    "                        ignore_patterns=[\"step_*\", \"epoch_*\"],\n",
    "                    )\n",
    "                else:\n",
    "                    model.save_pretrained(config.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kkj/ProtDiffusion/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac1e54fa422476e9390f6efa46530d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba0ab9996724e078fa8766973fec81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ee5c2d0e6147b9aa715dd6e192fdde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a197dc1e4f7843748098631a58431155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75169db3cee74bceaf201f1ef48b1332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d2804462144fbe8cb788dd99567a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4385b7e72933405d88076b3a49e4b292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481d92dd867a425cb5a91de9ec915f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fad6a8a1e2a4167b7e401777754a706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3573f79d5e324909b6866cebea5e7453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, val_loss: 3.0935, val_accuracy: 0.1247\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb67dbcd900b4ef69c9605fdc31bd30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2599e4f1bd104fe98e07175f6841dbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e73e5abe89246009a614ee7aa8781d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e27b4e07af544aca52fc41cac20e5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5efaae2beb4e95a8a9e5d2021ad315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76373529bcd46958c38f1601b3e9dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d7526395e04594834412dd2e08d989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b757c88c3df3402a86056d94a5f7eead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8cc915338446f7a55f139990400261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea5a7d17a564c879d1254ca892d392a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, val_loss: 3.0335, val_accuracy: 0.2044\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c5a31b40e74851b318ed485cecc9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3b8b1119ce4ac68d19020932d1d3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40944182f41494a905e4c3b75083bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea607c6be2724d2db0f503444ee3e40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289bae908f2c435eb6b383d8ed32f958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c48a79f3c64e2c9f4f041a1d1e4fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730411da00b94fc2ae889207af0c64bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95194bc90af4a83bf7c3c1954fea63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbb37d8b5cf4d7395e3fc6cdc393f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73260288ccf44514b25d9b170746f916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, val_loss: 2.9968, val_accuracy: 0.2442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8d8f9c106c4dc185011f5cf4d9da62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649b34c3d4284bf2aeb5db4ba4571113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9140df7463484d9bbb3218bbe52347c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882505d6448645d1825dc70763f931e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46be2e181d940dfb9dadb732f553a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cad70379b748bcae532a535e669514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d6886b1dcb4bd29e81d819a0236cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832e35de55194d82a67ba900d34b1e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d85ab4dac445f0bc7aa006a6f26be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba697b923ca40fd8886322faf3270af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, val_loss: 2.9753, val_accuracy: 0.2729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb9d2ed103245fe8b551cb97d26499b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973c4e5522d94666b40332029c16404a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df70add62f324a6bb9578b1fed0a5536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fbd220874f4cd48a5ad45da72d1eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26f4769949542ddbacf0cc801549817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7e3e40c68f4c6fb88bc74e8b740611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4046ac08c445d88630b474cc18f668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaebaa2ba5f84f84b34e5f75798f90d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4338fac4854444fbb316510c32d52749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66dbb8f3d094a57ac51cfb09a2bf4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, val_loss: 2.9548, val_accuracy: 0.2921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c2902062084dadb66568c2ca977c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee73c01e04940e5a720649794a4c228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe16241513af4d0bae9f29ae5cce7d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e2c7d244644cc0ba67bc5fe12f57bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eabb086ecc940009cdeb7895e1c896d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01f61b57333483cab4ca86e1d0ef409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcc7493e7b74e3d998df9019d98b7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5951daac4e4c258102b1c93ff6640a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0ca14a3eb949bb8d45bf99724dc843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4602def35edf46debbb76e844d0c1da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, val_loss: 2.9524, val_accuracy: 0.2966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6af4277641d48ae8d5c2a932b3f23e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e35b8110eaa41c3855d9993c9ebe037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261f906e52934104af96db623663bec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c813b77de6214de28abbce76067dd80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fda2aeb92f4e3c9352406679a3b863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ed6dde078048458607776d85f01e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbda0cf83d7f41fab8127bddf916ab48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2784d54cb8914ad7b56a297ae3b30f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48a568f69394abb9760f9f26cad75e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2dea311c7f4de3bd0989dee2d9d6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, val_loss: 2.9449, val_accuracy: 0.3046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07079073459f4f0093b55e639f6524af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c51e69a543245118657b3f4c9317760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809c4d4a4b1b4bd59b23b5cb9dded509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75945ef0e7cc4e469af9209289f1463f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07efdaf5021d4022afcf9500c77c924c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715dcf52e5fc438bb30691c36e7a4cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9095eb056244a49f28f623964568ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c6e9683bdf4ba2baf61b7e49e60493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7df79faded4d06929847e95ed71b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c6ac76202f4cbda5f6accb89b2fd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, val_loss: 2.9470, val_accuracy: 0.3025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9f6145f9df442db8578149aebdbdd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09210024bdbf4996b4e7b0acb806dd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1411a5de6604ed181febfd313f66025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66570ba8f6944b5b621e8591369b71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522df814935e43109064a4d1ff9f0e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef70f7d7af04222bf38dd37ba8264dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944abc03704046e79af0ca52377ff97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b832459d154f9bbc1ca8ade781ef4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2222afa7633f40b0b30ee6464725a448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809a7213d9d541bca1e97537c7200b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, val_loss: 2.9296, val_accuracy: 0.3220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8782b582717c4e78ae915e50bf02f0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851903e80db545d29b7f02e4f963bfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32dc77623414ca49a5d32b7221d9b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d476343f6c6d467eb2757222471b929c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76baadc8b9a4743839dec5358dabe13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cadebaf3c242078fe6936aac1a2845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1033f5fa013c4a0091061a69404935f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc7ae04ce60442c98b10ce21a2c92b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686086ffba854803a78701a4acf12b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6272edb04b64b62816a202f8e59ea0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, val_loss: 2.9269, val_accuracy: 0.3249\n"
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "\n",
    "args = (config, model, optimizer, test_dataloader, val_dataloader, lr_scheduler)\n",
    "\n",
    "notebook_launcher(train_loop, args, num_processes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
