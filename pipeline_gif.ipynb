{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Sinusoidal Positional Embeddings\n",
      "num_positional_embeddings:  256\n",
      "Using RoPE\n",
      "RoPE dim:  64\n"
     ]
    }
   ],
   "source": [
    "from ProtDiffusion.models.autoencoder_kl_1d import AutoencoderKL1D, AutoencoderKLOutput1D\n",
    "from ProtDiffusion.models.dit_transformer_1d import DiTTransformer1DModel\n",
    "from ProtDiffusion.models.pipeline_protein import ProtDiffusionPipeline, logits_to_token_ids\n",
    "from ProtDiffusion.visualization_utils import make_logoplot, plot_latent_and_probs\n",
    "from ProtDiffusion.training_utils import process_sequence, tokenize_sequence\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from diffusers import DDPMScheduler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_from_disk, Dataset, DatasetDict\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tokenizer: PreTrainedTokenizerFast = PreTrainedTokenizerFast.from_pretrained(\"/home/kkj/ProtDiffusion/ProtDiffusion/tokenizer/tokenizer_v4.2\")\n",
    "noise_scheduler: DDPMScheduler = DDPMScheduler(num_train_timesteps=1000, clip_sample=False)\n",
    "vae: AutoencoderKL1D = AutoencoderKL1D.from_pretrained('/home/kkj/ProtDiffusion/output/EMA_VAE_v24.12')\n",
    "transformer: DiTTransformer1DModel = DiTTransformer1DModel.from_pretrained('/home/kkj/ProtDiffusion/output/EMA-temp_DiT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831bbb4cccbb4c9cad463327b8c35509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TPESFGTSEAYKSLGRGILTDLFTTNDAKFHIHDDEIYDDVLIKTYEQKDKQGCDACVKWDVYRSFFWGARDGATLKFFSDIHNEKALFAFQNYPNCFDCPHVVVLDKITNKVLCDDNDYYRNKKRELGPDKEVKIPKRTPCDFYRRFYTPQSQDSFDVPEKLYDCVANFIHDLKPALGTTGDFLRYRTKETNGPLPAVPHELWRFSRCHNKPTPQEKNLFGRPPCIKCGKEPQKADDRGKLKECCRRILHLM]E\n"
     ]
    }
   ],
   "source": [
    "pipeline = ProtDiffusionPipeline(\n",
    "    transformer=transformer,\n",
    "    vae=vae,\n",
    "    scheduler=noise_scheduler,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "test_dir = os.path.join(\"temp\")\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "seqs_lens = [256]\n",
    "class_labels = [1]\n",
    "guidance_scale = 1.0\n",
    "eval_num_inference_steps = 10\n",
    "\n",
    "output = pipeline(seq_len=seqs_lens,\n",
    "                  class_labels=class_labels,\n",
    "                  guidance_scale=guidance_scale,\n",
    "                  num_inference_steps=eval_num_inference_steps,\n",
    "                  generator=None,\n",
    "                  output_type='aa_seq',\n",
    "                  return_hidden_latents=True,\n",
    "                  return_noise_pred=True,\n",
    "                  cutoff=None,\n",
    ")\n",
    "sequence = output.seqs\n",
    "print(sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['clusterid', 'proteinid', 'sequence', 'label', 'length'],\n",
       "    num_rows: 259393\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot some random latents\n",
    "dataset = load_from_disk('/home/kkj/ProtDiffusion/datasets/IPR036736_90')\n",
    "dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 0\n",
    "vae.eval()\n",
    "max_len = 256\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample = dataset[i]\n",
    "    sequence = sample['sequence']\n",
    "    sequence = process_sequence(sequence)\n",
    "    sequence = sequence[:max_len]\n",
    "    tokenized = tokenize_sequence(sequence, tokenizer)\n",
    "    input_ids = tokenized['input_ids']\n",
    "\n",
    "    vae_output: AutoencoderKLOutput1D = vae(input_ids)\n",
    "\n",
    "    # Plot the latents\n",
    "    scaled_latent = vae_output.latent_dist.mode()\n",
    "    latent = vae.config.scaling_factor * scaled_latent\n",
    "    logits = vae_output.sample\n",
    "    logits = logits[0].detach()\n",
    "    latent = latent[0].detach().cpu().numpy()\n",
    "    probs = F.softmax(logits, dim=0).detach().cpu().numpy()\n",
    "\n",
    "    # print(f\"Sequence: {sequence}\")\n",
    "    # print(f\"sequence length: {len(sequence)}\")\n",
    "    # print(f\"Latent shape: {latent}\")\n",
    "    # print(f\"Logits shape: {logits.shape}\")\n",
    "\n",
    "    plot_latent_and_probs(probs,\n",
    "                          latent,\n",
    "                          characters = tokenizer.decode(range(tokenizer.vocab_size)),\n",
    "                          path=f\"{test_dir}/latent_plot_{i}.png\",\n",
    "                          title=f\"Latent and probabilities for sample {i}\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animating inference of 11 steps\n",
      "Animating step 0\n",
      "Animating step 1\n",
      "Animating step 2\n",
      "Animating step 3\n",
      "Animating step 4\n",
      "Animating step 5\n",
      "Animating step 6\n",
      "Animating step 7\n",
      "Animating step 8\n",
      "Animating step 9\n",
      "Animating step 10\n",
      "Finished animating inference of 11 steps\n",
      "Saved images to temp/inference\n",
      "Creating gif...\n"
     ]
    }
   ],
   "source": [
    "pipeline.animate_inference(output, \n",
    "                           test_dir + \"/inference\",\n",
    "                           plot_noise=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
