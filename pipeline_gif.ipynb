{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProtDiffusion.models.autoencoder_kl_1d import AutoencoderKL1D, AutoencoderKLOutput1D\n",
    "from ProtDiffusion.models.dit_transformer_1d import DiTTransformer1DModel\n",
    "from ProtDiffusion.models.pipeline_protein import ProtDiffusionPipeline, logits_to_token_ids\n",
    "from ProtDiffusion.visualization_utils import make_logoplot, plot_latent_and_probs\n",
    "from ProtDiffusion.training_utils import process_sequence, tokenize_sequence\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from diffusers import DDPMScheduler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_from_disk, Dataset, DatasetDict\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tokenizer: PreTrainedTokenizerFast = PreTrainedTokenizerFast.from_pretrained(\"/home/kkj/ProtDiffusion/ProtDiffusion/tokenizer/tokenizer_v4.2\")\n",
    "noise_scheduler: DDPMScheduler = DDPMScheduler(num_train_timesteps=1000, clip_sample=False)\n",
    "vae: AutoencoderKL1D = AutoencoderKL1D.from_pretrained('/home/kkj/ProtDiffusion/output/EMA_VAE_v24.12')\n",
    "transformer: DiTTransformer1DModel = DiTTransformer1DModel.from_pretrained('/home/kkj/ProtDiffusion/output/RoPE_v3_temp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ProtDiffusionPipeline(\n",
    "    transformer=transformer,\n",
    "    vae=vae,\n",
    "    scheduler=noise_scheduler,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "test_dir = os.path.join(\"temp\")\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "seqs_lens = [256]\n",
    "class_labels = [1]\n",
    "guidance_scale = 0.0\n",
    "eval_num_inference_steps = 25\n",
    "\n",
    "output = pipeline(seq_len=seqs_lens,\n",
    "                  class_labels=class_labels,\n",
    "                  guidance_scale=guidance_scale,\n",
    "                  num_inference_steps=eval_num_inference_steps,\n",
    "                  generator=None,\n",
    "                  output_type='aa_seq',\n",
    "                  return_hidden_latents=True,\n",
    "                  return_noise_pred=True,\n",
    "                  cutoff=None,\n",
    ")\n",
    "sequence = output.seqs\n",
    "print(sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some random latents\n",
    "dataset = load_from_disk('/home/kkj/ProtDiffusion/datasets/IPR036736_90')\n",
    "dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 0\n",
    "vae.eval()\n",
    "max_len = 256\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample = dataset[i]\n",
    "    sequence = sample['sequence']\n",
    "    sequence = process_sequence(sequence)\n",
    "    sequence = sequence[:max_len]\n",
    "    tokenized = tokenize_sequence(sequence, tokenizer)\n",
    "    input_ids = tokenized['input_ids']\n",
    "\n",
    "    vae_output: AutoencoderKLOutput1D = vae(input_ids)\n",
    "\n",
    "    # Plot the latents\n",
    "    scaled_latent = vae_output.latent_dist.mode()\n",
    "    latent = vae.config.scaling_factor * scaled_latent\n",
    "    logits = vae_output.sample\n",
    "    logits = logits[0].detach()\n",
    "    latent = latent[0].detach().cpu().numpy()\n",
    "    probs = F.softmax(logits, dim=0).detach().cpu().numpy()\n",
    "\n",
    "    # print(f\"Sequence: {sequence}\")\n",
    "    # print(f\"sequence length: {len(sequence)}\")\n",
    "    # print(f\"Latent shape: {latent}\")\n",
    "    # print(f\"Logits shape: {logits.shape}\")\n",
    "\n",
    "    plot_latent_and_probs(probs,\n",
    "                          latent,\n",
    "                          characters = tokenizer.decode(range(tokenizer.vocab_size)),\n",
    "                          path=f\"{test_dir}/latent_plot_{i}.png\",\n",
    "                          title=f\"Latent and probabilities for sample {i}\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.animate_inference(output, \n",
    "                           test_dir + \"/inference\",\n",
    "                           plot_noise= True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
